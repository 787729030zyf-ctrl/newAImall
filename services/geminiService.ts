import { GoogleGenAI } from "@google/genai";

const getClient = () => {
  const apiKey = process.env.API_KEY;
  if (!apiKey) {
    throw new Error("API_KEY not found in environment");
  }
  return new GoogleGenAI({ apiKey });
};

/**
 * Uses Gemini to edit the user's uploaded image to apply makeup.
 */
export const applyMakeup = async (
  base64Image: string,
  instruction: string
): Promise<string> => {
  try {
    const ai = getClient();
    
    // Using gemini-2.5-flash-image for image editing capabilities
    // as per strict guidelines for "Edit Images"
    const model = 'gemini-2.5-flash-image';
    
    const response = await ai.models.generateContent({
      model,
      contents: {
        parts: [
          {
            inlineData: {
              data: base64Image,
              mimeType: 'image/jpeg', // Assuming jpeg for simplicity, or detect from source
            },
          },
          {
            text: `Apply the following makeup style to this face naturally: ${instruction}. Return only the edited image.`,
          },
        ],
      },
      // Config for image generation/editing
      // Note: responseMimeType is NOT supported for nano banana series (flash-image)
    });

    // Iterate to find image part
    if (response.candidates && response.candidates[0].content.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
           return part.inlineData.data;
        }
      }
    }

    throw new Error("No image generated by Gemini");

  } catch (error) {
    console.error("Gemini Makeup Error:", error);
    throw error;
  }
};